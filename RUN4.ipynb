{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parcels\n",
    "from parcels import Field,FieldSet,ParticleSet,Variable,JITParticle,AdvectionRK4,ErrorCode,BrownianMotion2D\n",
    "import datetime\n",
    "from datetime import timedelta as delta \n",
    "from glob import glob\n",
    "import math as m\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from operator import attrgetter\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from scipy.interpolate import griddata, Rbf\n",
    "from parcels import rng as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function and Kernels\n",
    "\n",
    "class PlasticParticle(JITParticle):  \n",
    "    u = Variable('u', dtype = np.float32)\n",
    "    v = Variable('v', dtype = np.float32)\n",
    "    beached = Variable('beached', dtype =np.float32, initial = 0 )\n",
    "    Kym1 = Variable('Kh_meridional', dtype = np.float32)\n",
    "    Kxm1 = Variable('Kh_zonal', dtype = np.float32)\n",
    "\n",
    "def Beached(particle, fieldset, time):\n",
    "    (u, v) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "    \n",
    "    if fabs(u) < 1e-18 and fabs(v) < 1e-18: #u,v never really = 0, instead use a really small number\n",
    "        particle.beached = 1                #1 = beached, 0 = sea\n",
    "    \n",

    "def Diffusion(particle, fiedlset, time):\n",
    "    if particle.beached == 0 :\n",
    "        #Parcels implemented kernel (AdvectionRK4DiffusionM1):\n",
    "        # RK4 terms\n",
    "        (u1, v1) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "        lon1, lat1 = (particle.lon + u1 * .5 * particle.dt, particle.lat + v1 * .5 * particle.dt)\n",
    "        (u2, v2) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat1, lon1]\n",
    "        lon2, lat2 = (particle.lon + u2 * .5 * particle.dt, particle.lat + v2 * .5 * particle.dt)\n",
    "        (u3, v3) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat2, lon2]\n",
    "        lon3, lat3 = (particle.lon + u3 * particle.dt, particle.lat + v3 * particle.dt)\n",
    "        (u4, v4) = fieldset.UV[time + particle.dt, particle.depth, lat3, lon3]\n",
    "\n",
    "        # Wiener increment with zero mean and std of sqrt(dt)\n",
    "        dWx = random.uniform(-1., 1.) * math.sqrt(math.fabs(particle.dt) * 3)\n",
    "        dWy = random.uniform(-1., 1.) * math.sqrt(math.fabs(particle.dt) * 3)\n",
    "\n",
    "        Kxp1 = fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon + fieldset.dres]\n",
    "        Kxm1 = fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon - fieldset.dres]\n",
    "        dKdx = (Kxp1 - Kxm1) / (2 * fieldset.dres)\n",
    "        bx = math.sqrt(2 * fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon])\n",
    "\n",
    "        Kyp1 = fieldset.Kh_meridional[time, particle.depth, particle.lat + fieldset.dres, particle.lon]\n",
    "        Kym1 = fieldset.Kh_meridional[time, particle.depth, particle.lat - fieldset.dres, particle.lon]\n",
    "        dKdy = (Kyp1 - Kym1) / (2 * fieldset.dres)\n",
    "        by = math.sqrt(2 * fieldset.Kh_meridional[time, particle.depth, particle.lat, particle.lon])\n",
    "\n",
    "        # Particle positions are updated only after evaluating all terms.\n",
    "        particle.lon += ((u1 + 2 * u2 + 2 * u3 + u4) / 6.) * particle.dt + 0.5 * dKdx * (dWx**2 + particle.dt) + bx * dWx\n",
    "        particle.lat += ((v1 + 2 * v2 + 2 * v3 + v4) / 6.) * particle.dt + 0.5 * dKdy * (dWy**2 + particle.dt) + by * dWy\n",
    "\n",
    "def periodicBC(particle, fieldset, time):\n",
    "    \"\"\"\n",
    "    Kernel for periodic values in longitude\n",
    "    \"\"\"\n",
    "    if particle.lon < 0.:\n",
    "        particle.lon += 360.\n",
    "    elif particle.lon >= 360.:\n",
    "        particle.lon -= 360.\n",
    "        \n",
    "def OutOfBounds(particle, fieldset, time):\n",
    "    particle.delete()\n",
    "    \n",
    "def set_currents (uvfiles):\n",
    "    #all in the same file\n",
    "    filenames = {'U': uvfiles,'V': uvfiles}\n",
    "    dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "    variables = {'U':'uo', 'V' : 'vo'}\n",
    "    uvindices = {'lon': range(2484, 2664), 'lat': range(1452, 1536)} #define domain \n",
    "   \n",
    "    \n",
    "    fset_currents = FieldSet.from_netcdf(filenames, variables, dimensions,allow_time_extrapolation = False, \n",
    "                                    indices = uvindices)\n",
    "    fset_currents.add_periodic_halo(zonal=True, meridional=False, halosize=5)\n",
    "    \n",
    "    return fset_currents\n",
    "\n",
    "\n",
    "def set_stokes(stokesfiles):\n",
    "    stokesfilenames = {'U': stokesfiles,'V': stokesfiles}\n",
    "    stokesdimensions = {'lon': 'longitude','lat': 'latitude', 'time': 'time'}\n",
    "    stokesvariables ={'U': 'uuss', 'V': 'uuss'}\n",
    "    \n",
    "    stokesindices = {'lon': range(420, 440), 'lat': range(237, 253)} #define domain    \n",
    "    \n",
    "\n",
    "    fset_stokes = FieldSet.from_netcdf(stokesfiles,stokesvariables,stokesdimensions,\n",
    "                                       allow_time_extrapolation = False, indices = stokesindices)\n",
    "    fset_stokes.add_periodic_halo(zonal=True, meridional=False, halosize=5)\n",
    "\n",
    "    \n",
    "    return fset_stokes\n",
    "\n",
    "def particles_grid(name, spacing = 0.2, minlon = 27, maxlon = 42, minlat = 41.5, maxlat = 47):\n",
    "    #Uniform grid of particles\n",
    "    \n",
    "    griddir = r'/data/oceanparcels/input_data/NEMO-MEDUSA/ORCA0083-N006/domain/bathymetry_ORCA12_V3.3.nc'\n",
    "    outdir= '/science-nfs-sys/vsm01/users/6312454/' + 'BS_grid'\n",
    "    \n",
    "    filename = griddir\n",
    "    data = Dataset(filename,'r')\n",
    "    bathy=np.array(data['Bathymetry'])\n",
    "    lon=np.array([data['nav_lon']][0])\n",
    "    lat=np.array([data['nav_lat']][0])\n",
    "    \n",
    "    grid=np.mgrid[minlon:maxlon:spacing,minlat:maxlat:spacing]\n",
    "    n=grid[0].size;\n",
    "    lons=np.reshape(grid[0],n)\n",
    "    lats=np.reshape(grid[1],n)\n",
    "      \n",
    "    points = np.array([lon.flatten(), lat.flatten()]).T\n",
    "    values = bathy.flatten()\n",
    "    xi = (lons, lats)\n",
    "    \n",
    "    bathy_p = griddata(points, values, xi, method='nearest')\n",
    "    \n",
    "    \n",
    "    Lons = np.array([lons[i] for i in range(len(lons)) if bathy_p[i] >17])\n",
    "    Lats = np.array([lats[i] for i in range(len(lats)) if bathy_p[i] >17])\n",
    "    \n",
    "    Lons[Lons<0.] += 360.\n",
    "    np.save(outdir + '_Longitude_' + str(name),Lons)\n",
    "    np.save(outdir + '_Latitude_' + str(name),Lats)\n",
    "\n",
    "    return Lons, Lats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "datadir = '/data/oceanparcels/input_data'\n",
    "\n",
    "stokesfiles = sorted(glob(datadir+'/WaveWatch3data/CFSR/WW3-GLOB-30M_*.nc'))\n",
    "uvfiles = sorted(glob(datadir +'/CMEMS/GLOBAL_REANALYSIS_PHY_001_030/mercatorglorys12v1_gl12_mean_*.nc'))\n",
    "\n",
    "##Coordinates particles grid\n",
    "name = '05'\n",
    "lons,lats = particles_grid(name)\n",
    "\n",
    "## Fiedlset \n",
    "currents = set_currents(uvfiles)\n",
    "stokes = set_stokes(stokesfiles)\n",
    "\n",
    "fset = FieldSet(U = currents.U, V = currents.V)\n",
    "fset_stokes = FieldSet(U =currents.U + stokes.U, V = currents.V + stokes.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Casting field data to np.float32\n"
     ]
    }
   ],
   "source": [
    "#Add field for BM2D\n",
    "\n",
    "size2D = (fset.U.grid.ydim, fset.U.grid.xdim)\n",
    "KH_z = 0.25\n",
    "alpha = 1\n",
    "L = fset.U.grid.ydim\n",
    "beta = np.zeros(fset.U.grid.ydim)\n",
    "y_K = fset.V.grid.lat\n",
    "\n",
    "for yi in range(len(y_K)):\n",
    "    if y_K[yi] < L/2:\n",
    "        beta[yi] = y_K[yi]*np.power(L - 2*y_K[yi], 1/alpha)\n",
    "    elif y_K[yi] >= L/2:\n",
    "        beta[yi] = (L - y_K[yi])*np.power(2*y_K[yi] - L, 1/alpha)\n",
    "\n",
    "KH_m = KH_z*(2*(1+alpha)*(1+2*alpha))/(alpha**2*np.power(L, 1+1/alpha))*beta\n",
    "Kh_meridional = np.array([KH_m for x in range(190)]).T\n",
    "\n",
    "\n",
    "fset.add_field(Field('Kh_zonal', data=KH_z*np.ones(size2D),lat=fset.U.grid.lat,lon=fset.U.grid.lon,\n",
    "                     mesh='spherical', allow_time_extrapolation=True))\n",
    "fset.add_field(Field('Kh_meridional', data=Kh_meridional*np.ones(size2D), \n",
    "                     #data=8 * np.ones(size2D),\n",
    "                     lon=fset.U.grid.lon,lat=fset.U.grid.lat,mesh='spherical', allow_time_extrapolation=True))\n",
    "\n",
    "fset.add_constant('dres', 0.00002)\n",
    "\n",
    "fset_stokes.add_field(Field('Kh_zonal', data=KH_z*np.ones(size2D),lat=fset.U.grid.lat,lon=fset.U.grid.lon,\n",
    "                     mesh='spherical', allow_time_extrapolation=True))\n",
    "fset_stokes.add_field(Field('Kh_meridional', data=Kh_meridional*np.ones(size2D), \n",
    "                            #data=8 * np.ones(size2D),\n",
    "                            lon=fset.U.grid.lon,lat=fset.U.grid.lat,mesh='spherical', \n",
    "                            allow_time_extrapolation=True))\n",
    "\n",
    "fset_stokes.add_constant('dres', 0.00002)"
   ]
  },

   "source": [
    "###RUN 4\n",
    "\n",
    "startlats = lats\n",
    "startlons = lons\n",
    "startlons = [l + 360 for l in startlons]\n",
    "\n",
    "\n",
    "rundays = 30\n",
    "dt = 30         #[min]\n",
    "nperloc = 30\n",
    "\n",
    "starttime = datetime.datetime(2015,1,1,0,0)\n",
    "starttime = np.repeat(starttime, len(startlats))\n",
    "\n",
    "repeatdt = delta(days=30)\n",
    "\n",
    "\n",
    "\n",
    "psetname ='RUN_4testDiffusion'\n",
    "\n",
    "name = str(psetname)+str(rundays)+'d_'+str(dt)+'m'   #outputfile name\n",
    "\n",
    "\n",
    "pset_RUN4 = ParticleSet(fieldset=fset_stokes, pclass=PlasticParticle, lon=np.repeat(startlons, [nperloc]),\n",
    "                        lat=np.repeat(startlats, [nperloc]), time=np.repeat(starttime, [nperloc])\n",
    "                        #,repeatdt = repeatdt\n",
    "                       )\n",
    "\n",
    "kernels = pset_RUN4.Kernel(AdvectionRK4) + Beached + periodicBC + Diffusion +Speed + Kh\n",
    "\n",
    "pset_RUN4.execute(kernels, runtime = delta(days = rundays), dt = delta(minutes= dt),\n",
    "                    output_file = pset_RUN4.ParticleFile(name = name, outputdt=delta(hours=12)), \n",
    "                    recovery = {ErrorCode.ErrorOutOfBounds: OutOfBounds},verbose_progress =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

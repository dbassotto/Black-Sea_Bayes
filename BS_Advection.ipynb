{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import Field,FieldSet,ParticleSet,Variable,JITParticle,AdvectionRK4,ErrorCode,VectorField\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta as delta \n",
    "from glob import glob\n",
    "\n",
    "import math as m\n",
    "from operator import attrgetter\n",
    "\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function and Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function and Kernels\n",
    "\n",
    "class PlasticParticle(JITParticle):  \n",
    "    # Define a new particle class that contains three extra variables\n",
    "    beached = Variable('beached', dtype =np.float32, initial = 0 )\n",
    "    \n",
    "def Beached(particle, fieldset, time):\n",
    "    \"\"\"\n",
    "    Kernel to calculate the number of stranded particles\n",
    "    \"\"\"\n",
    "    (u,v) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "    \n",
    "    #u,v never really = 0, instead use a really small number\n",
    "    if fabs(u) <= 1e-20 and fabs(v) <= 1e-20 : \n",
    "        particle.beached = 1       #beached = 1, sea = 0\n",
    "        \n",
    "\n",
    "def set_fieldset(stokes, currents, fieldset):\n",
    "    \"\"\"\n",
    "    Kernel to set the fieldset: Stokes drift added only off-coasts\n",
    "    \"\"\"\n",
    "    \n",
    "    (u,v) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "\n",
    "    if fabs(u) <= 1e-20 and fabs(v) <= 1e-20 : \n",
    "        fset = FieldSet(U = u, V  = v)\n",
    "    elif fabs(u) > 1e-20 and fabs(v) > 1e-20: \n",
    "        fset = FieldSet(U = u + u_uss, V = v + v_uss)\n",
    "\n",
    "        \n",
    "    return fset\n",
    "\n",
    "def DiffusionM1(particle, fiedlset, time):\n",
    "    \"\"\" \n",
    "    Parcels implemented kernel (AdvectionRK4DiffusionM1):\n",
    "    \"\"\"\n",
    "    if particle.beached == 0 :\n",
    "\n",
    "        # RK4 terms\n",
    "        (u1, v1) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "        lon1, lat1 = (particle.lon + u1 * .5 * particle.dt, particle.lat + v1 * .5 * particle.dt)\n",
    "        (u2, v2) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat1, lon1]\n",
    "        lon2, lat2 = (particle.lon + u2 * .5 * particle.dt, particle.lat + v2 * .5 * particle.dt)\n",
    "        (u3, v3) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat2, lon2]\n",
    "        lon3, lat3 = (particle.lon + u3 * particle.dt, particle.lat + v3 * particle.dt)\n",
    "        (u4, v4) = fieldset.UV[time + particle.dt, particle.depth, lat3, lon3]\n",
    "\n",
    "        # Wiener increment with zero mean and std of sqrt(dt)\n",
    "        dWx = random.uniform(-1., 1.) * math.sqrt(math.fabs(particle.dt) * 3)\n",
    "        dWy = random.uniform(-1., 1.) * math.sqrt(math.fabs(particle.dt) * 3)\n",
    "\n",
    "        Kxp1 = fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon + fieldset.dres]\n",
    "        Kxm1 = fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon - fieldset.dres]\n",
    "        dKdx = (Kxp1 - Kxm1) / (2 * fieldset.dres)\n",
    "        bx = math.sqrt(2 * fieldset.Kh_zonal[time, particle.depth, particle.lat, particle.lon])\n",
    "\n",
    "        Kyp1 = fieldset.Kh_meridional[time, particle.depth, particle.lat + fieldset.dres, particle.lon]\n",
    "        Kym1 = fieldset.Kh_meridional[time, particle.depth, particle.lat - fieldset.dres, particle.lon]\n",
    "        dKdy = (Kyp1 - Kym1) / (2 * fieldset.dres)\n",
    "        by = math.sqrt(2 * fieldset.Kh_meridional[time, particle.depth, particle.lat, particle.lon])\n",
    "\n",
    "        # Particle positions are updated only after evaluating all terms.\n",
    "        particle.lon += ((u1 + 2 * u2 + 2 * u3 + u4) / 6.) * particle.dt + 0.5 * dKdx * (dWx**2 + particle.dt) + bx * dWx\n",
    "        particle.lat += ((v1 + 2 * v2 + 2 * v3 + v4) / 6.) * particle.dt + 0.5 * dKdy * (dWy**2 + particle.dt) + by * dWy\n",
    "\n",
    "\n",
    "def periodicBC(particle, fieldset, time):\n",
    "    \"\"\"\n",
    "    Kernel for periodic values in longitude\n",
    "    \"\"\"\n",
    "    if particle.lon < 0.:\n",
    "        particle.lon += 360.\n",
    "    elif particle.lon >= 360.:\n",
    "        particle.lon -= 360.\n",
    "        \n",
    "def OutOfBounds(particle, fieldset, time):\n",
    "    particle.delete()\n",
    "    \n",
    "def set_currents (uvfiles):\n",
    "    \"\"\"\n",
    "    Surface currents only\n",
    "    \"\"\"\n",
    "    #all in the same file (CMEMS reanalysis)\n",
    "    filenames = {'U': uvfiles,\n",
    "            'V': uvfiles}\n",
    "    dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "    variables = {'U':'uo', 'V' : 'vo'}\n",
    "    uvindices = {'lon': range(2484, 2664), 'lat': range(1452, 1536)} #define domain \n",
    "   \n",
    "    \n",
    "    fset_currents = FieldSet.from_netcdf(filenames, variables, dimensions,allow_time_extrapolation = False, \n",
    "                                    indices = uvindices)\n",
    "    fset_currents.add_periodic_halo(zonal=True, meridional=False, halosize=5)\n",
    "    \n",
    "    return fset_currents\n",
    "\n",
    "def set_stokes(stokesfiles, fieldset):\n",
    "    \"\"\"\n",
    "    Kernel to add Stokes drift to the surface currents\n",
    "    \"\"\"\n",
    "    stokesfilenames = {'Uuss': stokesfiles,\n",
    "            'Vuss': stokesfiles}\n",
    "    stokesdimensions = {'lon': 'longitude','lat': 'latitude', 'time': 'time'}\n",
    "    stokesvariables ={'Uuss': 'uuss', 'Vuss': 'vuss'}\n",
    "    \n",
    "    stokesindices = {'lon': range(420, 440), 'lat': range(237, 253)} #define domain    \n",
    "    \n",
    "    Uuss = Field.from_netcdf(stokesfiles, ('Uuss', 'uuss'), stokesdimensions, fieldtype='U', \n",
    "                            allow_time_extrapolation=False,indices = stokesindices)\n",
    "    Vuss = Field.from_netcdf(stokesfiles, ('Vuss', 'vuss'), stokesdimensions, fieldtype='V', \n",
    "                            allow_time_extrapolation=False, \n",
    "                            grid=Uuss.grid, dataFiles=Uuss.dataFiles, indices = stokesindices)\n",
    "    \n",
    "    fieldset.add_field(Uuss)\n",
    "    fieldset.add_field(Vuss)\n",
    "    uv_uss = VectorField('UVuss', fieldset.Uuss, fieldset.Vuss)\n",
    "    fieldset.add_vector_field(uv_uss)\n",
    "\n",
    "\n",
    "def BrownianMotion(particle, fieldset, time): #from Erik\n",
    "    if beached == 0 : \n",
    "        kh_zonal = fieldset.Kh / math.pow(1000. * 1.852 * 60. * math.cos(particle.lat * math.pi / 180), 2)\n",
    "        kh_meridional = fieldset.Kh / math.pow(1000.0 * 1.852 * 60.0, 2)\n",
    "\n",
    "        r = 1/3.\n",
    "        particle.lat += random.uniform(-1., 1.)*math.sqrt(2*math.fabs(dt)*kh_meridional/r)\n",
    "        particle.lon += random.uniform(-1., 1.)*math.sqrt(2*math.fabs(dt)*kh_zonal/r)\n",
    "\n",
    "def particles_grid(name, spacing = 0.15, minlon = 27, maxlon = 42, minlat = 41.5, maxlat = 47):\n",
    "    \"\"\"\n",
    "    Kernel to create an uniform grid of particles for initial positions\n",
    "    @author: David Wichmann, modified by Deborah Bassotto\n",
    "    \"\"\"\n",
    "    \n",
    "    griddir = r'/data/oceanparcels/input_data/NEMO-MEDUSA/ORCA0083-N006/domain/bathymetry_ORCA12_V3.3.nc'\n",
    "    outdir= '/science-nfs-sys/vsm01/users/6312454/' + 'BS_grid'\n",
    "    \n",
    "    filename = griddir\n",
    "    data = Dataset(filename,'r')\n",
    "    bathy=np.array(data['Bathymetry'])\n",
    "    lon=np.array([data['nav_lon']][0])\n",
    "    lat=np.array([data['nav_lat']][0])\n",
    "    \n",
    "    grid=np.mgrid[minlon:maxlon:spacing,minlat:maxlat:spacing]\n",
    "    n=grid[0].size;\n",
    "    lons=np.reshape(grid[0],n)\n",
    "    lats=np.reshape(grid[1],n)\n",
    "      \n",
    "    points = np.array([lon.flatten(), lat.flatten()]).T\n",
    "    values = bathy.flatten()\n",
    "    xi = (lons, lats)\n",
    "    \n",
    "    bathy_p = griddata(points, values, xi, method='nearest')\n",
    "    \n",
    "    \n",
    "    Lons = np.array([lons[i] for i in range(len(lons)) if bathy_p[i] >17])\n",
    "    Lats = np.array([lats[i] for i in range(len(lats)) if bathy_p[i] >17])\n",
    "    \n",
    "    Lons[Lons<0.] += 360.\n",
    "    np.save(outdir + '_Longitude_' + str(name),Lons)\n",
    "    np.save(outdir + '_Latitude_' + str(name),Lats)\n",
    "\n",
    "    return Lons, Lats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data\n",
    "outdir= '/science-nfs-sys/vsm01/users/6312454/' + 'BS_grid'\n",
    "datadir = '/data/oceanparcels/input_data'\n",
    "\n",
    "stokesfiles = sorted(glob(datadir+'/WaveWatch3data/CFSR/WW3-GLOB-30M_*.nc'))\n",
    "uvfiles = sorted(glob(datadir +'/CMEMS/GLOBAL_REANALYSIS_PHY_001_030/mercatorglorys12v1_gl12_mean_*.nc'))\n",
    "\n",
    "##Coordinates particles grid\n",
    "name = '05'\n",
    "lons,lats = particles_grid(name)\n",
    "\n",
    "\n",
    "print('Number of initial particles'+ '\\t' + str(len(lons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating fieldset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without Stokes drift\n",
    "currents = set_currents(uvfiles)\n",
    "fset = FieldSet(U = currents.U, V = currents.V)\n",
    "\n",
    "##With Stokes drift\n",
    "stokes = set_stokes(stokesfiles, fset)\n",
    "fset_stokes = FieldSet(U =currents.U + stokes.U, V = currents.V + stokes.V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Field for diffusion\n",
    "\n",
    "From [GrÃ¤we (2011)](https://www.sciencedirect.com/science/article/abs/pii/S1463500310001484?via%3Dihub)$\\;$ (or check [Parcels Diffusion Tutorial](https://nbviewer.jupyter.org/github/OceanParcels/parcels/blob/master/parcels/examples/tutorial_diffusion.ipynb)).\n",
    "\n",
    "<br>\n",
    "\n",
    "$ K_{meridional}(y) = \\bar{K}\\frac{2(1+\\alpha)(1+2\\alpha)}{\\alpha^2 H^{1+1/\\alpha}} \\begin{cases}y(L-2y)^{1/\\alpha}\\;\\textrm{and}\\; 0 \\leq y \\leq L/2, \\\\ (L-y)(2y-1)^{1/\\alpha}\\; \\textrm{and} \\; H/2 \\leq y \\leq L \\end{cases}$.\n",
    "\n",
    "\n",
    "<br>\n",
    "NB : If the dataset as values for Kh, this can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size2D = (fset.U.grid.ydim, fset.U.grid.xdim)\n",
    "KH_z = 0.25\n",
    "alpha = 0.1\n",
    "L = fset.U.grid.ydim\n",
    "beta = np.zeros(fset.U.grid.ydim)\n",
    "y_K = fset.V.grid.lat\n",
    "\n",
    "for yi in range(len(y_K)):\n",
    "    if y_K[yi] < L/2:\n",
    "        beta[yi] = y_K[yi]*np.power(L - 2*y_K[yi], 1/alpha)\n",
    "    elif y_K[yi] >= L/2:\n",
    "        beta[yi] = (L - y_K[yi])*np.power(2*y_K[yi] - L, 1/alpha)\n",
    "\n",
    "KH_m = KH_z*(2*(1+alpha)*(1+2*alpha))/(alpha**2*np.power(L, 1+1/alpha))*beta\n",
    "Kh_meridional = np.array([KH_m for x in range(190)]).T\n",
    "\n",
    "\n",
    "fset.add_field(Field('Kh_zonal', data=KH_z*np.ones(size2D),lat=fset.U.grid.lat,lon=fset.U.grid.lon,\n",
    "                     mesh='spherical', allow_time_extrapolation=True))\n",
    "fset.add_field(Field('Kh_meridional', data=Kh_meridional*np.ones(size2D), \n",
    "                     #data=8 * np.ones(size2D),\n",
    "                     lon=fset.U.grid.lon,lat=fset.U.grid.lat,mesh='spherical', allow_time_extrapolation=True))\n",
    "\n",
    "fset.add_constant('dres', 0.000002)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial uniform particles position over the Black-Sea\n",
    "startlats = lats\n",
    "startlons = lons\n",
    "startlons = [l + 360 for l in startlons]\n",
    "\n",
    "\n",
    "rundays = 365   #[days]\n",
    "dt = 30         #[min]\n",
    "nperloc = 20    #Number of particle released per location\n",
    "\n",
    "starttime = datetime.datetime(2015,1,1,0,0)\n",
    "starttime = np.repeat(starttime, len(startlats))\n",
    "\n",
    "#Uncomment if you want to release new partciles every x-time\n",
    "#repeatdt = delta(days=30) \n",
    "\n",
    "psetname ='RUN4_test'\n",
    "\n",
    "name = str(psetname)+str(rundays)+'d'  #outputfile name\n",
    "\n",
    "\n",
    "pset_RUN4 = ParticleSet(fieldset=fset, pclass=PlasticParticle, lon=np.repeat(startlons, [nperloc]),\n",
    "                        lat=np.repeat(startlats, [nperloc]), time=np.repeat(starttime, [nperloc])\n",
    "                        #,repeatdt = repeatdt\n",
    "                       )\n",
    "\n",
    "kernels = pset_RUN4.Kernel(AdvectionRK4) + periodicBC + DiffusionM1 + Beached + StokesDrag\n",
    "\n",
    "##Executing the simulation\n",
    "pset_RUN4.execute(kernels, runtime = delta(days = rundays), dt = delta(minutes= dt),\n",
    "                    output_file\n",
    "                  = pset_RUN4.ParticleFile(name = name, outputdt=delta(hours=12)), \n",
    "                    recovery = {ErrorCode.ErrorOutOfBounds: OutOfBounds},verbose_progress =False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
